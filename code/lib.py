"""
Helper functions for use by scripts and notebooks

"""

__all__ = [
    "prepare_df_for_plotting",
    "plot_results",
    "plot_timeseries_predictions",
    "plot_overall_results",
    "ProgressBar",
]

import matplotlib.pyplot as plt
import seaborn as sns
from asyncio import Event
import ray
from ray.actor import ActorHandle
from tqdm import tqdm
from typing import Tuple
from pathlib import Path
from matplotlib import rcParams

sns.set_context(
    "talk",
    font_scale=1.2,
    rc={"font.sans-serif": "Avenir", "font-family": "sans-serif"},
)
sns.set_style("whitegrid")
rcParams["font.sans-serif"] = ["Avenir"]
rcParams["font.family"] = "sans-serif"


def plot_timeseries_predictions(
    model,
    figsize=(8, 6),
    n_boot=500,
    minval=-1,
    maxval=101,
    xlabel="Time",
    ylabel="Rating",
    ax=None,
    title="",
    title_fontsize=22,
    remove_legend=False,
):
    """
    Given a model who's predictions should be treated as a time-series, make a lineplot of the observed and predicted ratings

    Args:
        model (emotioncf model): a model object
        figsize (tuple, optional): figure size. Defaults to (8, 6).
        n_boot (int, optional): number of bootstraps for error bands. Defaults to 500.
        minval (int, optional): min y-limit. Defaults to -1.
        maxval (int, optional): max y-limit. Defaults to 101.
        context (str, optional): seaborn context for plot. Defaults to "talk".
        font_scale (float, optional): seaborn context font scaling for plot. Defaults to 1.2.
        axes_style (str, optional): seaborn axes style. Defaults to "white".
        xlabel (str, optional): xlabel. Defaults to "Time".
        ylabel (str, optional): ylabel. Defaults to "Rating".

    Returns:
        tuple: (axis subplot, figure handle)
    """
    df = model.to_long_df()
    if ax is None:
        _, ax = plt.subplots(1, 1, figsize=figsize)
    ax = sns.lineplot(
        x="Item", y="Rating", hue="Condition", data=df, n_boot=n_boot, ax=ax
    )
    if remove_legend:
        ax.get_legend().remove()
    else:
        ax.legend(loc="upper left").set_title(None)
    ax.set(
        xlabel=xlabel,
        ylabel=ylabel,
        ylim=(minval, maxval),
    )
    ax.set_title(title, fontsize=title_fontsize)
    sns.despine()
    return ax


def prepare_df_for_plotting(
    df,
    dataset_name: str,
    df_type="overall",
    dataset="missing",
    group="user",
    metric="rmse",
    normalize=None,
    dimension=None,
    dilation=None,
):
    """
    Prepare a results csv file generated by the fit_all_models.py script for plotting

    Args:
        df (pd.DataFrame): overall results dataframe
        group (str): "user" or "all"; Default "user"
        metric (str): "correlation", "mse", "mae", or "rmse"; Default "rmse"
        dimension (str): name of dimension to filtery by; Default None (retains all)
        dilation (str): dilation to filtery by; Default None (retains all)

    Returns:
        pd.DataFrame: modified input dataframe
    """

    out = df.copy()
    if "Subject" in out.columns:
        out = out.rename(columns={"Subject": "user"})
    elif "workerId" in out.columns:
        out = out.rename(columns={"workerId": "user"})

    if df_type == "overall":
        # Get just the mean user performance for this metric
        out = out.query(
            "dataset == @dataset and group == @group and metric == @metric"
        ).reset_index(drop=True)

    else:
        col_name = f"{metric}_{dataset}"
        # Get requested performance for this metric and dataset
        cols = [
            "user",
            col_name,
            "iter",
            "train_size",
            "dimension",
            "algorithm",
            "n_factors",
            "dilation",
        ]
        out = out[cols]
        # Make consistent with overall df for plotting purposes
        out["metric"] = metric
        # Mean across iterations with user
        cols = [
            "user",
            "train_size",
            "dimension",
            "algorithm",
            "metric",
            "n_factors",
            "dilation",
        ]
        out = (
            out.groupby(cols)[col_name]
            .mean()
            .reset_index()
            .rename(columns={col_name: "score"})
        )
    # Handle potentionally multiple dilations
    if dilation is not None:
        out = out.query("dilation == @dilation").reset_index(drop=True)

    # Handle multiple dimensions
    if dimension is not None:
        out = out.query("dimension == @dimension").reset_index(drop=True)

    # Rename train_size
    out["Samples_Perc"] = out.train_size.map(
        dict(
            zip(
                sorted(out.train_size.unique()),
                ["10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%"],
            )
        )
    )
    model_rename_map = {
        "Mean": "Mean",
        "MICE": "MICE",
        "KNN": "KNN (k=10)",
        "NNMF_M": "NNMF (mult)",
        "NNMF_S": "NNMF (sgd)",
    }
    out["algorithm"] = out["algorithm"].map(model_rename_map)
    if normalize is not None:
        if dataset_name != "decisions":
            out["score"] /= normalize
        else:
            out["score"] = out.apply(
                lambda row: row["score"] / normalize
                if row["dimension"] == "Returned"
                else row["score"],
                axis=1,
            )
    return out


def uniquify_legend():
    """
    Removes duplicate legend labels when plotting multiple seaborn plots to the same axis. Uses the current axis so call this after making a plot. Then use the output of the function like so:

    ax.legend(labels.values(),labels.keys())

    Returns:
        labels: dictionary of unique labels and legends
    """

    handles, labels = plt.gca().get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    return by_label


def plot_overall_results(
    data,
    filter_data=True,
    hide_nmf_m=False,
    show_nmf_dil=False,
    save=False,
    ax=None,
    **kwargs,
):
    """
    Makes a strippoint plot with training % on the x-axis and error on the y-axis with algorithms as hues. By default expects in the output of prepare_df_for_plotting which doesn't filter data down to dilation == 0 and no dimensionality reduction, so this is done by default

    Args:
        data (pd.DataFrame): output of prepare_df_for_plotting
        filter (bool): filter data down to dilation == 0 and no dimensionality reduction; Default True
        hide_nmf_m (bool): hide the NNMF_mult algorithm; Default False
        save (bool): save a jpg and pdf of the plot; Default False
    """
    figsize = kwargs.get("figsize", (12, 6))
    alpha = kwargs.get("alpha", 0.02)
    n_boot = kwargs.get("n_boot", 500)
    xlabel = kwargs.get("xlabel", "Observed Data")
    ylabel = kwargs.get("ylabel", "Normalized Error")
    title = kwargs.get("title", "")
    title_fontsize = kwargs.get("title_fontsize", 26)
    ylim = kwargs.get("ylim", None)

    if filter_data:
        df = data.query("dilation == 0 and n_factors == 'all'").reset_index(drop=True)
    else:
        df = data

    if show_nmf_dil:
        algos = ["KNN (k=10)", "MICE", "Mean", "NNMF (sgd)", "NNMF (sgd)_5"]
        df = df.query("algorithm in @algos and n_factors == 'all'").reset_index(
            drop=True
        )
        df["algorithm"] = df.algorithm.map(
            {
                "KNN (k=10)": "KNN (k=10)",
                "MICE": "MICE",
                "Mean": "Mean",
                "NNMF (sgd)": "NNMF (sgd)",
                "NNMF (sgd)_5": "NNMF (sgd 5s)",
            }
        )

    if hide_nmf_m:
        df = df.query("algorithm != 'NNMF (mult)'").reset_index(drop=True)
        hue_order = [
            "Mean",
            "KNN (k=10)",
            "NNMF (sgd)",
            "MICE",
        ]
    else:
        hue_order = [
            "Mean",
            "KNN (k=10)",
            "NNMF (sgd)",
            "NNMF (mult)",
            "MICE",
        ]
    if ax is None:
        _, ax = plt.subplots(1, 1, figsize=figsize)

    _ = sns.stripplot(
        x="Samples_Perc",
        y="score",
        hue="algorithm",
        order=sorted(df.Samples_Perc.unique()),
        hue_order=hue_order,
        data=df,
        alpha=alpha,
        ax=ax,
    )
    _ = sns.pointplot(
        x="Samples_Perc",
        y="score",
        hue="algorithm",
        units="user",
        order=sorted(df.Samples_Perc.unique()),
        hue_order=hue_order,
        data=df,
        legend=False,
        n_boot=n_boot,
        ax=ax,
    )

    labels = uniquify_legend()
    ax.legend(
        labels.values(),
        labels.keys(),
        bbox_to_anchor=(1.14, 1),
        borderaxespad=0,
        frameon=False,
    )
    ax.set(ylabel=ylabel, xlabel=xlabel, ylim=ylim)
    if title:
        ax.set_title(title, fontsize=title_fontsize)
    sns.despine()
    plt.tight_layout()
    if save:
        if isinstance(save, Path):
            if not save.parent.exists():
                save.parent.mkdir()
        plt.savefig(f"{save}.pdf", bbox_inches="tight")
        plt.savefig(f"{save}.jpg", bbox_inches="tight")
    return ax


def plot_results(
    df,
    dataset_name: str,
    df_type="user",
    save=False,
    height=5,
    aspect=1.5,
    legend=True,
    ci=95,
    col=None,
    row=None,
    col_wrap=None,
    facet_kws={"legend_out": True},
    title_padding=0.98,
    title=None,
    sharey=True,
    ylabel=None,
    context="talk",
    font_scale=1.2,
    axes_style="whitegrid",
    ylim=None,
    tight_layout=False,
    hide_nmf_m=False,
    average_marginals=True,
    **kwargs,
):

    if ylabel is None:
        metric = df.metric.unique()[0]
        if metric == "correlation":
            ylabel = "Mean Correlation"
        elif metric == "rmse":
            ylabel = "Mean RMSE"
        elif metric == "mse":
            ylabel = "Mean MSE"
        elif metric == "mae":
            ylabel = "Mean MAE"
        else:
            raise ValueError("metric should be 'correlation' or 'rmse'")

    if title is None:
        title = dataset_name.capitalize()
    if hide_nmf_m:
        hue_order = ["Mean", "KNN (k=10)", "NNMF (sgd)", "MICE"]
        df = df.query("algorithm != 'NNMF (mult)'").reset_index(drop=True)
    else:
        hue_order = ["Mean", "KNN (k=10)", "NNMF (sgd)", "NNMF (mult)", "MICE"]
    order = ["10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%"]

    if dataset_name == "decisions":
        if row == "dimension":
            row, row_order = "dimension", ["Prop_Returned", "Returned"]
        elif row == "n_factors":
            row, row_order = "n_factors", sorted(df.n_factors.unique())[::-1]
        elif row == "phenotype":
            row, row_order = "phenotype", [
                "Guilt Averse",
                "Greedy",
                "Moral Opportunist",
                "Inequity Averse",
            ]
        else:
            row, row_order = None, None
        if col == "dimension":
            col, col_order = "dimension", ["Prop_Returned", "Returned"]
        elif col == "n_factors":
            col, col_order = "n_factors", sorted(df.n_factors.unique())[::-1]
        elif col == "phenotype":
            col, col_order = "phenotype", [
                "Guilt Averse",
                "Greedy",
                "Moral Opportunist",
                "Inequity Averse",
            ]
        else:
            col, col_order = None, None

    elif dataset_name == "iaps":
        if row == "dimension":
            row, row_order = "dimension", [
                "anger",
                "disgust",
                "fear",
                "surprise",
                "sadness",
                "joy",
            ]
        elif row == "n_factors":
            row, row_order = "n_factors", sorted(df.n_factors.unique())[::-1]
        else:
            row, row_order = None, None
        if col == "dimension":
            col, col_order = "dimension", [
                "anger",
                "disgust",
                "fear",
                "surprise",
                "sadness",
                "joy",
            ]
        elif col == "n_factors":
            col, col_order = "n_factors", sorted(df.n_factors.unique())[::-1]
        else:
            col, col_order = None, None

    elif dataset_name == "moth":
        if col == "dimension":
            col, col_order = "dimension", [
                "GMarksTheSpot",
                "StrangerBonding",
                "BestOfTimes",
                "ThisIsGoingToSuck",
                "Mortified",
                "FindingHome",
                "CopsDontCry",
                "UnexpectedTwist",
            ]
        elif col == "dilation":
            col, col_order = "dilation", sorted(df["dilation"].unique())
        elif col == "n_factors":
            col, col_order = "n_factors", sorted(df.n_factors.unique())[::-1]
        else:
            col, col_order = None, None
        if row == "dimension":
            row, row_order = "dimension", [
                "GMarksTheSpot",
                "StrangerBonding",
                "BestOfTimes",
                "ThisIsGoingToSuck",
                "Mortified",
                "FindingHome",
                "CopsDontCry",
                "UnexpectedTwist",
            ]
        elif row == "dilation":
            row, row_order = "dilation", sorted(df["dilation"].unique())
        elif row == "n_factors":
            row, row_order = "n_factors", sorted(df.n_factors.unique())[::-1]
        else:
            row, row_order = None, None

    if col == "n_factors" or row == "n_factors":
        just_nmf = True
        dfp = df.query("algorithm in ['NNMF (mult)', 'NNMF (sgd)']")
    else:
        dfp = df
        just_nmf = False

    # Make sure if we don't facet on dilation or n_factors, the data is subset on
    # no dilation and no dimensionality reduction
    if not average_marginals:
        if row != "dilation" or col != "dilation":
            dfp = dfp.query("dilation == 0").reset_index(drop=True)

        if row != "n_factors" or col != "n_factors":
            dfp = dfp.query("n_factors == 'all'").reset_index(drop=True)

    # dfp["algorithm"] = dfp["algorithm"].astype("category")
    with sns.plotting_context(
        "talk",
        font_scale=1.2,
        rc={"font.sans-serif": "Avenir", "font-family": "sans-serif"},
    ):
        g = sns.catplot(
            x="Samples_Perc",
            y="score",
            hue="algorithm",
            units="iter" if df_type == "overall" else "user",
            kind="point",
            ci=ci,
            hue_order=hue_order[-2:] if just_nmf else hue_order,
            order=order,
            row=row,
            row_order=row_order,
            col=col,
            col_order=col_order,
            col_wrap=col_wrap,
            height=height,
            aspect=aspect,
            legend=legend,
            data=dfp,
            facet_kws=facet_kws,
            sharey=sharey,
            palette=sns.color_palette(n_colors=5)[-2:] if just_nmf else None,
            **kwargs,
        )
        g.set_axis_labels("Training Data Size", ylabel)
        if dataset_name == "decisions":
            g.set_titles(col_template="{col_name}")
            g.set_ylabels("")
            g.fig.text(0, 0.35, "Normalized Error", fontsize=22, rotation=90)
            g.set_xlabels("")
            g.fig.text(0.4, 0.0, "Observed Data", fontsize=22)
        g.legend.set_title(None)

        if ylim is not None:
            g.set(ylim=ylim)
        if title_padding is not None:
            plt.subplots_adjust(top=title_padding)
        g.fig.suptitle(title, x=0.47)
        sns.despine()
        if tight_layout:
            plt.tight_layout()
        if save:
            if isinstance(save, Path):
                if not save.parent.exists():
                    save.parent.mkdir()
            plt.savefig(f"{save}.pdf", bbox_inches="tight")
            plt.savefig(f"{save}.jpg", bbox_inches="tight")
        else:
            return g


@ray.remote
class ProgressBarActor:
    counter: int
    delta: int
    event: Event

    def __init__(self) -> None:
        self.counter = 0
        self.delta = 0
        self.event = Event()

    def update(self, num_items_completed: int) -> None:
        """Updates the ProgressBar with the incremental
        number of items that were just completed.
        """
        self.counter += num_items_completed
        self.delta += num_items_completed
        self.event.set()

    async def wait_for_update(self) -> Tuple[int, int]:
        """Blocking call.

        Waits until somebody calls `update`, then returns a tuple of
        the number of updates since the last call to
        `wait_for_update`, and the total number of completed items.
        """
        await self.event.wait()
        self.event.clear()
        saved_delta = self.delta
        self.delta = 0
        return saved_delta, self.counter

    def get_counter(self) -> int:
        """
        Returns the total number of complete items.
        """
        return self.counter


class ProgressBar:
    progress_actor: ActorHandle
    total: int
    description: str
    pbar: tqdm

    def __init__(self, total: int, description: str = ""):
        """
        A tqdm progressbar that works across parallel ray processes. In the script that submits the ray tasks, just create a ProgressBar with the total number of tasks and make sure the function you're going to parallelize takes an ActorHandle argument and calls .update.remote(1) on it when done.

        Args:
            total (int): number of iterations
            description (str, optional): progress bar description. Defaults to "".

        Examples:

            >>>  pb = ProgressBar(num_tasks)
            >>>  actor = pb.actor
            >>> @ray.remote
            >>> def myfunc(i: int, pb: ActorHandle):
            >>> ... # some computation
            >>>     pb.update.remote(1)
            >>>     return
            >>> futures = [myfunc.remote(i, actor) for i in range(num_tasks)]
            >>>  pb.print_until_done()
            >>>  results = ray.get(futures)

        """
        self.progress_actor = ProgressBarActor.remote()  # type: ignore
        self.total = total
        self.description = description

    @property
    def actor(self) -> ActorHandle:
        """Returns a reference to the remote `ProgressBarActor`.

        When you complete tasks, call `update` on the actor.
        """
        return self.progress_actor

    def print_until_done(self) -> None:
        """Blocking call.

        Do this after starting a series of remote Ray tasks, to which you've
        passed the actor handle. Each of them calls `update` on the actor.
        When the progress meter reaches 100%, this method returns.
        """
        pbar = tqdm(desc=self.description, total=self.total)
        while True:
            delta, counter = ray.get(self.actor.wait_for_update.remote())
            pbar.update(delta)
            if counter >= self.total:
                pbar.close()
                return
